# chatbot.py
# Ch·∫°y b·∫±ng: streamlit run chatbot.py
# Y√™u c·∫ßu: pip install google-generativeai streamlit
import os
import time
import traceback
import streamlit as st
import google.generativeai as genai  # ƒë√∫ng import cho SDK m·ªõi

# --- L·∫§Y API KEY ---
# Tr√™n Streamlit Cloud: th√™m GEMINI_API_KEY (ho·∫∑c GOOGLE_API_KEY) v√†o Secrets
API_ENV_NAMES = ("GEMINI_API_KEY", "GOOGLE_API_KEY", "API_KEY")
api_key = None
for name in API_ENV_NAMES:
    api_key = os.getenv(name) or api_key
if not api_key:
    try:
        api_key = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY") or st.secrets.get("API_KEY")
    except Exception:
        api_key = None

if not api_key:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y API key. Th√™m GEMINI_API_KEY (ho·∫∑c GOOGLE_API_KEY) v√†o m√¥i tr∆∞·ªùng / Streamlit secrets.")
    st.stop()

# --- VAI TR√í / SYSTEM INSTRUCTION (gi·ªØ nguy√™n n·ªôi dung d√†i c·ªßa th·∫ßy) ---
SYSTEM_INSTRUCTION = """ 
B·∫°n l√† ‚ÄúChatbook‚Äù, m·ªôt C·ªë v·∫•n H·ªçc t·∫≠p Tin h·ªçc AI to√†n di·ªán.
... (gi·ªØ nguy√™n to√†n b·ªô n·ªôi dung SYSTEM_INSTRUCTION nh∆∞ trong file g·ªëc c·ªßa th·∫ßy) ...
"""

# --- MODEL ---
MODEL_NAME = st.secrets.get("MODEL_NAME", "MODEL_NAME = "gemini-1.5-pro") if isinstance(st.secrets, dict) else os.getenv("MODEL_NAME", "MODEL_NAME = "gemini-1.5-pro")

# C·∫•u h√¨nh SDK
try:
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"L·ªói khi c·∫•u h√¨nh genai SDK: {e}")
    st.stop()

# Kh·ªüi t·∫°o model object (s·ª≠ d·ª•ng t√™n model)
try:
    # GenerativeModel ch·∫•p nh·∫≠n t√™n model nh∆∞ tham s·ªë kh·ªüi t·∫°o
    model = genai.GenerativeModel(MODEL_NAME)
except Exception as e:
    st.error(f"L·ªói khi t·∫°o model object: {e}")
    st.stop()

# --- Streamlit UI & CSS ---
st.set_page_config(page_title="Chatbot Tin h·ªçc 2018", page_icon="‚ú®", layout="centered")
st.markdown("""
<style>
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
    [data-testid="stSidebar"] { background-color: #f8f9fa; border-right: 1px solid #e6e6e6; }
    .main .block-container { max-width: 850px; padding-top: 2rem; padding-bottom: 5rem; }
    .welcome-message { font-size: 1.1em; color: #333; }
</style>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.title("ü§ñ Chatbot KTC")
    st.markdown("---")
    if st.button("‚ûï Cu·ªôc tr√≤ chuy·ªán m·ªõi", use_container_width=True):
        st.session_state.messages = []
        st.session_state.pop("knowledge_chunks", None)
        st.experimental_rerun()
    st.markdown("---")
    st.markdown(
        "Gi√°o vi√™n h∆∞·ªõng d·∫´n:\n"
        "**Th·∫ßy Nguy·ªÖn Th·∫ø Khanh** (GV Tin h·ªçc)\n\n"
        "H·ªçc sinh th·ª±c hi·ªán:\n"
        "*(B√πi T√° T√πng)*\n"
        "*(Cao S·ªπ B·∫£o Chung)*"
    )
    st.markdown("---")
    st.caption(f"Model: {MODEL_NAME}")

# --- Kh·ªüi t·∫°o session state ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "knowledge_chunks" not in st.session_state:
    st.session_state.knowledge_chunks = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Logo & title (kh√¥ng stop app n·∫øu thi·∫øu logo ‚Äî ch·ªâ c·∫£nh b√°o)
logo_path = "LOGO.jpg"
col1, col2 = st.columns([1, 5])
with col1:
    try:
        st.image(logo_path, width=80)
    except Exception:
        st.warning(f"Kh√¥ng t√¨m th·∫•y file logo '{logo_path}' ‚Äî ti·∫øp t·ª•c ch·∫°y kh√¥ng c√≥ logo.")
with col2:
    st.title("KTC. Chatbot h·ªó tr·ª£ m√¥n Tin H·ªçc")

def set_prompt_from_suggestion(text):
    st.session_state.prompt_from_button = text

# G·ª£i √Ω ban ƒë·∫ßu n·∫øu ch∆∞a c√≥ cu·ªôc tr√≤ chuy·ªán
if not st.session_state.messages:
    st.markdown("<div class='welcome-message'>Xin ch√†o! Th·∫ßy/em c·∫ßn h·ªó tr·ª£ g√¨ v·ªÅ m√¥n Tin h·ªçc (Ch∆∞∆°ng tr√¨nh 2018)?</div>", unsafe_allow_html=True)
    col1_btn, col2_btn = st.columns(2)
    with col1_btn:
        st.button("Gi·∫£i th√≠ch v·ªÅ 'bi·∫øn' trong l·∫≠p tr√¨nh?", on_click=set_prompt_from_suggestion, args=("Gi·∫£i th√≠ch v·ªÅ 'bi·∫øn' trong l·∫≠p tr√¨nh?",), use_container_width=True)
        st.button("Tr√¨nh b√†y v·ªÅ an to√†n th√¥ng tin?", on_click=set_prompt_from_suggestion, args=("Tr√¨nh b√†y v·ªÅ an to√†n th√¥ng tin?",), use_container_width=True)
    with col2_btn:
        st.button("S·ª± kh√°c nhau gi·ªØa RAM v√† ROM?", on_click=set_prompt_from_suggestion, args=("S·ª± kh√°c nhau gi·ªØa RAM v√† ROM?",), use_container_width=True)
        st.button("C√°c b∆∞·ªõc ch√®n ·∫£nh v√†o word", on_click=set_prompt_from_suggestion, args=("C√°c b∆∞·ªõc ch√®n ·∫£nh v√†o word",), use_container_width=True)

# --- X·ª≠ l√Ω input ---
prompt_from_input = st.chat_input("M·ªùi th·∫ßy ho·∫∑c c√°c em ƒë·∫∑t c√¢u h·ªèi v·ªÅ Tin h·ªçc...")
prompt_from_button = st.session_state.pop("prompt_from_button", None)
prompt = prompt_from_button or prompt_from_input

def build_prompt(system_instruction, history, user_input, max_history_chars=8000):
    """
    Gom system instruction + l·ªãch s·ª≠ + user_input v√†o m·ªôt prompt text.
    C·∫Øt l·ªãch s·ª≠ n·∫øu qu√° d√†i d·ª±a tr√™n max_history_chars (ƒë∆°n gi·∫£n).
    """
    # T·∫°o vƒÉn b·∫£n l·ªãch s·ª≠: m·ªói turn "User: ...\nAssistant: ..."
    hist_lines = []
    for m in history:
        role = "User" if m["role"] == "user" else "Assistant"
        # escape or normalize newline sequences if c·∫ßn
        content = m["content"].strip()
        hist_lines.append(f"{role}: {content}")
    conversation = "\n".join(hist_lines)
    full = f"{system_instruction}\n\n{conversation}\nUser: {user_input}\nAssistant:"
    # N·∫øu qu√° d√†i, gi·ªØ ph·∫ßn cu·ªëi c·ªßa conversation (ƒë∆°n gi·∫£n)
    if len(full) > max_history_chars:
        keep = full[-max_history_chars:]
        return keep
    return full

if prompt:
    # Add user message to history and show it
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Prepare prompt and call Gemini (synchronously)
    try:
        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("ƒêang suy nghƒ©...")

            prompt_text = build_prompt(SYSTEM_INSTRUCTION, st.session_state.messages[:-1], prompt)

            try:
                # G·ªçi API: generate_content tr·∫£ v·ªÅ object c√≥ .text
                response = model.generate_content(prompt_text)
                bot_response_text = getattr(response, "text", str(response))
                if not bot_response_text:
                    bot_response_text = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi cho truy v·∫•n n√†y."
            except Exception as api_err:
                # Hi·ªán l·ªói chi ti·∫øt (traceback) cho ng∆∞·ªùi qu·∫£n tr·ªã
                bot_response_text = f"‚ö†Ô∏è L·ªói khi g·ªçi Gemini API: {api_err}"
                # Log chi ti·∫øt (d√πng traceback ƒë·ªÉ debug tr√™n Streamlit logs)
                st.error(bot_response_text)
                st.error(traceback.format_exc())

            # Hi·ªán k·∫øt qu·∫£
            placeholder.markdown(bot_response_text)

    except Exception as e:
        # N·∫øu c√≥ l·ªói ngo√†i d·ª± ki·∫øn
        with st.chat_message("assistant"):
            st.error(f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói n·ªôi b·ªô: {e}")
            st.error(traceback.format_exc())
        bot_response_text = f"L·ªñI N·ªòI B·ªò: {e}"

    # L∆∞u c√¢u tr·∫£ l·ªùi n·∫øu c√≥
    if bot_response_text:
        st.session_state.messages.append({"role": "assistant", "content": bot_response_text})

# N√∫t x√≥a cu·ªôc tr√≤ chuy·ªán (l∆∞u √Ω: ƒë√£ ƒë·∫∑t ·ªü sidebar nh∆∞ng ƒë·ªÉ th√™m n·ªØa)
if st.button("üîÑ X√≥a h·ªôi tho·∫°i"):
    st.session_state.messages = []
    st.experimental_rerun()

st.markdown("---")
st.caption("¬© 2025 ‚Ä¢ Chatbot Gemini | X√¢y d·ª±ng b·ªüi gi√°o vi√™n Tin h·ªçc & AI ü§ñ")



